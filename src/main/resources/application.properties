server.port=8078
spring.application.name=MachinumApp
spring.servlet.multipart.max-file-size=20MB
spring.servlet.multipart.max-request-size=20MB
spring.threads.virtual.enabled=true
spring.mvc.log-resolved-exception=true
server.error.include-message=always
server.error.include-stacktrace=never
server.error.include-exception=false
spring.autoconfigure.exclude=org.springframework.ai.model.image.observation.autoconfigure.ImageObservationAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiAudioTranscriptionAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiChatAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiEmbeddingAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiImageAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiModerationAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiAudioSpeechAutoConfiguration
spring.thymeleaf.cache=false
spring.resources.chain.cache=false
spring.resources.cache.cachecontrol.no-cache=true
spring.jackson.default-property-inclusion=non_null
spring.jackson.mapper.default-view-inclusion=true
spring.jackson.mapper.accept-case-insensitive-enums=true
management.endpoints.web.exposure.include=*
management.endpoint.shutdown.enabled=true
endpoints.shutdown.enabled=true
spring.jpa.open-in-view=false
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.jdbc.batch_size=50
hibernate.jdbc.batch_size=50
spring.ai.chat.client.enabled=false
spring.ai.openai.api-key=00-00-00-0000000000000000000000000000000000000000000000000000000000000000
spring.ai.openai.base_url=${OPENAI_BASE_URL:https://openrouter.ai/api}
spring.ai.openai.chat.options.model=deepseek/deepseek-r1:free
spring.ai.openai.chat.options.temperature=0.1
spring.ai.ollama.base-url=http://localhost:7869
spring.ai.ollama.chat.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
spring.ai.ollama.chat.options.temperature=0.5
spring.ai.ollama.chat.options.numCtx=10240
spring.ai.gemini.chat.options.model=GEMINI_2_0_FLASH_EXP
spring.ai.gemini.token=000000000000000000000000000000000000000
spring.ai.gemini-ai.chat.options.model=gemini-2.0-flash-exp
spring.ai.gemini-ai.token=000000000000000000000000000000000000000
spring.ai.ollama.transform.options.model=deepseek-r1:32b
spring.ai.ollama.transform.options.temperature=0.3
spring.ai.ollama.transform.options.stop=nodata_nodata_nodata
spring.ai.ollama.transform.options.numCtx=16384
spring.ai.ollama.transform.options.format=json
spring.ai.ollama.embedding.enabled=false
spring.ai.ollama.embedding.model=nomic-embed-text
spring.ai.ollama.init.timeout=15m
spring.ai.ollama.init.max-retries=3
spring.ai.retry.max-attempts=3
spring.ai.retry.backoff.multiplier=5
spring.ai.openrouter.chat.options.models[0]=deepseek/deepseek-r1:free
spring.ai.openrouter.chat.options.models[1]=tngtech/deepseek-r1t2-chimera:free
spring.ai.openrouter.chat.options.models[2]=openai/gpt-oss-20b:free
spring.ai.openrouter.chat.options.models[3]=qwen/qwen3-coder:free
spring.ai.openrouter.chat.options.models[4]=qwen/qwen3-235b-a22b:free
spring.ai.openrouter.chat.options.models[5]=qwen/qwen3-14b:free
spring.ai.openrouter.chat.options.models[6]=qwen/qwen-2.5-coder-32b-instruct:free
spring.ai.openrouter.chat.options.models[7]=qwen/qwen3-30b-a3b:free
spring.ai.openrouter.chat.options.models[8]=qwen/qwen-2.5-72b-instruct:free
spring.ai.openrouter.chat.options.models[9]=qwen/qwq-32b:free
spring.ai.openrouter.chat.options.models[10]=z-ai/glm-4.5-air:free
spring.ai.openrouter.chat.options.models[11]=google/gemma-3-27b-it:free
spring.ai.openrouter.chat.options.models[12]=google/gemini-2.0-flash-exp:free
#spring.ai.openrouter.chat.options.models[0]=deepseek/deepseek-chat-v3-0324
#spring.ai.openrouter.chat.options.models[1]=deepseek/deepseek-r1-0528
#spring.ai.openrouter.chat.options.models[2]=qwen/qwen3-coder
#spring.ai.openrouter.chat.options.models[3]=deepseek/deepseek-r1
#spring.ai.openrouter.chat.options.models[4]=z-ai/glm-4.5-air
#spring.ai.openrouter.chat.options.models[5]=tngtech/deepseek-r1t2-chimera
#spring.ai.openrouter.chat.options.models[6]=moonshotai/kimi-k2
#spring.ai.openrouter.chat.options.models[7]=tngtech/deepseek-r1t-chimera
#spring.ai.openrouter.chat.options.models[8]=google/gemini-2.0-flash-exp
#spring.ai.openrouter.chat.options.models[9]=qwen/qwen3-235b-a22b
#spring.ai.openrouter.chat.options.models[10]=openai/gpt-oss-20b
#spring.ai.openrouter.chat.options.models[11]=meta-llama/llama-3.3-70b-instruct
#spring.ai.openrouter.chat.options.models[12]=microsoft/mai-ds-r1
#spring.ai.openrouter.chat.options.models[13]=deepseek/deepseek-r1-0528-qwen3-8b
#spring.ai.openrouter.chat.options.models[14]=mistralai/mistral-small-3.2-24b-instruct
#spring.ai.openrouter.chat.options.models[15]=qwen/qwen2.5-vl-72b-instruct
#spring.ai.openrouter.chat.options.models[16]=mistralai/mistral-small-3.1-24b-instruct
#spring.ai.openrouter.chat.options.models[17]=cognitivecomputations/dolphin-mistral-24b-venice-edition
#spring.ai.openrouter.chat.options.models[18]=mistralai/mistral-nemo
#spring.ai.openrouter.chat.options.models[19]=qwen/qwen3-14b
#spring.ai.openrouter.chat.options.models[20]=qwen/qwen-2.5-coder-32b-instruct
#spring.ai.openrouter.chat.options.models[21]=google/gemma-3-27b-it
#spring.ai.openrouter.chat.options.models[22]=tencent/hunyuan-a13b-instruct
#spring.ai.openrouter.chat.options.models[23]=moonshotai/kimi-dev-72b
#spring.ai.openrouter.chat.options.models[24]=deepseek/deepseek-r1-distill-llama-70b
#spring.ai.openrouter.chat.options.models[25]=qwen/qwen3-30b-a3b
#spring.ai.openrouter.chat.options.models[26]=agentica-org/deepcoder-14b-preview
#spring.ai.openrouter.chat.options.models[27]=mistralai/mistral-7b-instruct
#spring.ai.openrouter.chat.options.models[28]=meta-llama/llama-3.1-405b-instruct
#spring.ai.openrouter.chat.options.models[29]=qwen/qwen-2.5-72b-instruct
#spring.ai.openrouter.chat.options.models[30]=mistralai/devstral-small-2505
#spring.ai.openrouter.chat.options.models[31]=moonshotai/kimi-vl-a3b-thinking
#spring.ai.openrouter.chat.options.models[32]=qwen/qwen2.5-vl-32b-instruct
#spring.ai.openrouter.chat.options.models[33]=qwen/qwen3-8b
#spring.ai.openrouter.chat.options.models[34]=nousresearch/deephermes-3-llama-3-8b-preview
#spring.ai.openrouter.chat.options.models[35]=qwen/qwq-32b
#spring.ai.openrouter.chat.options.models[36]=meta-llama/llama-3.2-11b-vision-instruct
#spring.ai.openrouter.chat.options.models[37]=cognitivecomputations/dolphin3.0-mistral-24b
#spring.ai.openrouter.chat.options.models[38]=qwen/qwen3-4b
#spring.ai.openrouter.chat.options.models[39]=google/gemma-3n-e2b-it
#spring.ai.openrouter.chat.options.models[40]=shisa-ai/shisa-v2-llama3.3-70b
#spring.ai.openrouter.chat.options.models[41]=google/gemma-3-12b-it
#spring.ai.openrouter.chat.options.models[42]=arliai/qwq-32b-arliai-rpr-v1
#spring.ai.openrouter.chat.options.models[43]=google/gemma-2-9b-it
#spring.ai.openrouter.chat.options.models[44]=mistralai/mistral-small-24b-instruct-2501
#spring.ai.openrouter.chat.options.models[45]=cognitivecomputations/dolphin3.0-r1-mistral-24b
#spring.ai.openrouter.chat.options.models[46]=meta-llama/llama-3.2-3b-instruct
#spring.ai.openrouter.chat.options.models[47]=google/gemma-3n-e4b-it
#spring.ai.openrouter.chat.options.models[48]=featherless/qwerky-72b
#spring.ai.openrouter.chat.options.models[49]=google/gemma-3-4b-it
#spring.ai.openrouter.chat.options.models[50]=sarvamai/sarvam-m
#spring.ai.openrouter.chat.options.models[51]=nvidia/llama-3.1-nemotron-ultra-253b-v1
#spring.ai.openrouter.chat.options.models[52]=rekaai/reka-flash-3
#spring.ai.openrouter.chat.options.models[53]=deepseek/deepseek-r1-distill-qwen-14b

spring.datasource.password=pgvector
spring.datasource.username=pgvector
spring.datasource.database-name=pgvector
spring.datasource.url=jdbc:postgresql://localhost:5432/pgvector?reWriteBatchedInserts=true
spring.flyway.enabled=true
spring.flyway.baseline-on-migrate=true
spring.ai.vectorstore.pgvector.dimensions=384
#spring.ai.vectorstore.pgvector.tableName=vector_store_384
#spring.ai.vectorstore.pgvector.index-type=HNSW
#spring.ai.vectorstore.pgvector.distance-type=COSINE_DISTANCE
#spring.ai.vectorstore.pgvector.dimensions=1536
#spring.ai.vectorstore.pgvector.batching-strategy=TOKEN_COUNT # Optional.Controls how documents are batched for embedding
#spring.ai.vectorstore.pgvector.max-document-batch-size=10000 # Optional.Maximum number of documents per batch
#spring.cache.cache-names=store
#spring.cache.caffeine.spec=maximumSize=500,expireAfterAccess=60m
#logging.level.org.zalando.logbook=TRACE
logging.level.machinum.config.OpenRouterConfig=TRACE
logging.level.org.springframework.web.filter.CustomRequestLoggingFilter=DEBUG
logging.level.org.springframework.ai.transformer.splitter.TextSplitter=WARN
logging.level.machinum=DEBUG
#logging.level.machinum=INFO
logbook.format.style=curl
logging.file.max-history=1
logging.file.max-size=10MB
logging.file.total-size-cap=100MB
logging.file.name=build/logs/log.txt
app.batch-size=50
app.run-id=${random.uuid}
app.mode=production
app.flow.cooldown=30s
app.http.logs-path=build/http-logs
app.http.logs-enabled=true
#max,min,normal
app.convert-mode=min
# single|springstandard|springmin|lines|whitespaces|balancedlines|balancedsentence|default
app.parallel.enabled=true
app.flow.batch-size=10
#app.cache.type=local
#app.cache.folder=build/cache
app.cache.ttl=14d
assets.cache.folder=build/cache/resources
assets.cache.metadata-file=build/cache/dynamic_cache_metadata.json
app.split.mode=balancedsentence
app.split.overlap=512
app.split.overlap-size=100
# chunks|chunkswithmessage|message|makeuptext|default
#app.history.mode=chunks
app.history.mode=makeupatext
app.compress.mode=simple
app.compress.percentage=50
app.allow-tools=false
app.rewrite.template=Rewrite.ST
app.rewrite.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.rewrite.temperature=0.8
app.rewrite.numCtx=10240
app.rewrite.provider=ollama
app.summary.model=gpt-oss:20b
app.summary.temperature=0.3
app.summary.numCtx=14336
app.summary.consolidate.model=qwen2.5:32b
app.summary.consolidate.temperature=0.8
app.summary.consolidate.numCtx=10240
app.glossary.extract.model=gpt-oss:20b
app.glossary.extract.temperature=0.3
app.glossary.extract.numCtx=14336
app.glossary.extract.provider=ollama
app.logic-splitter.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.logic-splitter.temperature=0.8
app.logic-splitter.numCtx=10240
app.logic-splitter.chunk-size=640
app.proofread.en.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.proofread.en.temperature=0.6
app.proofread.en.numCtx=10240
app.proofread.en.provider=ollama
app.proofread.ru.model=hf.co/t-tech/T-pro-it-1.0-Q6_K-GGUF:latest
app.proofread.ru.temperature=0.7
app.proofread.ru.numCtx=10240
app.glossary.translate.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.glossary.translate.temperature=0.2
app.glossary.translate.numCtx=10240
#app.glossary.translate.provider=ollama
app.translate.model=hf.co/t-tech/T-pro-it-1.0-Q6_K-GGUF:latest
app.translate.temperature=0.8
app.translate.numCtx=10240
app.translate.provider=ollama
app.translate.fail-on-wrong-chunks=false
app.translate.title.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.translate.title.temperature=0.8
app.translate.title.numCtx=4096
#app.translate.title.provider=ollama
app.translate.scoring.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.translate.scoring.temperature=0.8
app.translate.scoring.numCtx=10240
app.translate.scoring.responseLength=1024
app.translate.score.iterations=2
app.translate.score.quality=9
app.translate.copy-editing.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.translate.copy-editing.temperature=0.8
app.translate.copy-editing.numCtx=10240
# ollama | gemini
app.translate.copy-editing.provider=ollama
# auto | min
app.translate.copy-editing.history.mode=min
app.translate.copy-editing-scoring.model=hf.co/lmstudio-community/gemma-3-27b-it-GGUF:Q6_K
app.translate.copy-editing-scoring.temperature=0.8
app.translate.copy-editing-scoring.numCtx=10240
app.ssml.model=hf.co/t-tech/T-pro-it-1.0-Q6_K-GGUF:latest
app.ssml.temperature=0.7
app.ssml.numCtx=8192
app.ssml.chunkSize=1280
app.minio.endpoint=http://minio:9000
app.minio.enabled=false
app.minio.check-enabled=false
app.minio.console=http://minio:9001
app.minio.accessKey=minio
app.minio.secretKey=minio123
app.minio.bucketName=tts-audio
app.tts-service.url=http://tts:5003
app.tts-service.cover-url=none
app.tts-service.metadata.title=Sample Title
app.tts-service.metadata.artist=Sample Artist
app.tts-service.metadata.album=Sample Album
# Placeholder {year} automatically will be replaced to current year
app.tts-service.metadata.year={year}
app.tts-service.metadata.genre=AudioBook
# ISO 639-3 == rus | eng
app.tts-service.metadata.language=eng
app.tts-service.metadata.track=1
app.tts-service.metadata.publisher=Sample Publisher
app.tts-service.metadata.copyright=© {year} Sample Copyright
app.tts-service.metadata.comments=This is a sample comment.
app.ma-service.url=http://localhost:8076
app.ma-service.script=translate-script